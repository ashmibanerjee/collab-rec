{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-01T20:05:55.053184Z",
     "start_time": "2026-02-01T20:05:55.036146Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T19:59:48.659110Z",
     "start_time": "2026-02-01T19:59:48.641161Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MODELS = ['claude', 'gemini', 'gpt', 'gemma-12b', 'olmo-7b', 'gemma-4b']\n",
    "REJECTION_STRATEGIES = [\"aggressive\", \"majority\"]"
   ],
   "id": "21ea823cf741b280",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T21:08:12.448379Z",
     "start_time": "2026-02-01T21:08:12.420985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_data(model: str, rejection_strategy: str) -> pd.DataFrame:\n",
    "    path = f\"../data/collab-rec-2026/analysis/{model}_mami_{rejection_strategy}_scores_with_relevance.csv\"\n",
    "    return pd.read_csv(path)"
   ],
   "id": "f7131444bd03591b",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T21:17:17.617311Z",
     "start_time": "2026-02-01T21:17:17.581100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def hall_rel_score(model, rejection_strategy) -> float:\n",
    "    print(f\"== {model} {rejection_strategy} ===\")\n",
    "    df = load_data(model, rejection_strategy )\n",
    "    mami_df = df.loc[(df[\"agent_name\"].isin([\"personalization\", \"sustainability\", \"popularity\"])) & (df[\"round_nr\"]==10)]\n",
    "    masi_df = df.loc[(df[\"agent_name\"].isin([\"personalization\", \"sustainability\", \"popularity\"])) & (df[\"round_nr\"]==1)]\n",
    "    print(f\"\\t Hall. Rate:\\n MASI: {np.mean(masi_df['hallucination_rate'])} \\n MAMI: {np.mean(mami_df['hallucination_rate'])}\")\n",
    "    print(f\"\\t Rel. Score: MAMI: {np.mean(mami_df['reliability_score']):.4f}\")"
   ],
   "id": "4f6af547942474a",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T21:17:19.554724Z",
     "start_time": "2026-02-01T21:17:18.065964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for rs in REJECTION_STRATEGIES:\n",
    "    for model in MODELS:\n",
    "        print(model, rs)\n",
    "        hall_rel_score(model, rs)"
   ],
   "id": "b6e2dc67de571125",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Hall. Rate:\n",
      " MASI: 0.0023703703703703686 \n",
      " MAMI: 0.0\n",
      "\t Rel. Score: MAMI: 0.9613\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T21:40:23.045740Z",
     "start_time": "2026-02-01T21:40:23.025363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from experiments.helpers import load_queries\n",
    "from constants import CITIES\n",
    "\n",
    "def get_hall_score(cities: list):\n",
    "    if not cities:\n",
    "        return None\n",
    "    hall_count = sum(1 for city in cities if city not in CITIES)\n",
    "    return hall_count / len(cities)\n",
    "\n",
    "def hall_score_sasi(model):\n",
    "    data = load_queries(f\"../data/collab-rec-2026/llm-results/{model}/sasi/{model}_sasi.json\")\n",
    "\n",
    "    total_hall_score = 0\n",
    "    count = 0\n",
    "\n",
    "    for item in data:\n",
    "        responses = item.get('response', [])\n",
    "        if not responses:\n",
    "            continue\n",
    "\n",
    "        result = responses[0]\n",
    "        cities = result.get('cities') or result.get('candidates')\n",
    "\n",
    "        if cities:\n",
    "            total_hall_score += get_hall_score(cities)\n",
    "            count += 1\n",
    "\n",
    "    avg_hall_score = total_hall_score / count if count > 0 else 0\n",
    "\n",
    "    print(f\"avg hall score sasi: {model}: {avg_hall_score}\")"
   ],
   "id": "a43e64a0a4b78715",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T21:40:35.330806Z",
     "start_time": "2026-02-01T21:40:35.010595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for model in MODELS:\n",
    "    hall_score_sasi(model)"
   ],
   "id": "ce5035bc7d619f87",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg hall score sasi: olmo-7b: 0.04751930896292888\n",
      "avg hall score sasi: gemma-4b: 0.00655555555555555\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T21:40:58.040681Z",
     "start_time": "2026-02-01T21:40:57.983339Z"
    }
   },
   "cell_type": "code",
   "source": "hall_score_sasi(\"gemma-12b\")",
   "id": "e86c51516162d341",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg hall score sasi: gemma-12b: 0.005555555555555553\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d0ca10422fccc4f8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
